{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, os\n",
    "from torch.utils.data import Dataset\n",
    "from ipywidgets import interact \n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\liang\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\trec\\f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2 (last modified on Mon Aug 21 17:19:17 2023) since it couldn't be found locally at trec., or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"trec\")\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text' : train_dataset['text'], 'coarse_label' : train_dataset['coarse_label']})\n",
    "test_df = pd.DataFrame({'text' : test_dataset['text'], 'coarse_label' : test_dataset['coarse_label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>coarse_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  coarse_label\n",
       "0  How did serfdom develop in and then leave Russ...             2\n",
       "1   What films featured the character Popeye Doyle ?             1\n",
       "2  How can I find a list of celebrities ' real na...             2\n",
       "3  What fowl grabs the spotlight after the Chines...             1\n",
       "4                    What is the full form of .com ?             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "initial_labeled_set, pool = train_test_split(train_df, test_size=0.95, stratify=train_df['coarse_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>coarse_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>What was the name of the `` Little Rascals '' ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>What 2th-century American poet wrote a four-vo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>Where is your corpus callosum ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>What actor first portrayed James Bond ?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>What is the origin of the surname of Braun ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>What are equity securities ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>How many Gutenberg Bibles are there ?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>What is her husband 's name ?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>What good are mosquitoes ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>What is the fine for having a dog on a beach ?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  coarse_label\n",
       "141   What was the name of the `` Little Rascals '' ...             1\n",
       "4222  What 2th-century American poet wrote a four-vo...             3\n",
       "2870                    Where is your corpus callosum ?             4\n",
       "353             What actor first portrayed James Bond ?             3\n",
       "945        What is the origin of the surname of Braun ?             2\n",
       "...                                                 ...           ...\n",
       "137                        What are equity securities ?             2\n",
       "917               How many Gutenberg Bibles are there ?             5\n",
       "2384                      What is her husband 's name ?             3\n",
       "4768                         What good are mosquitoes ?             2\n",
       "2968     What is the fine for having a dog on a beach ?             5\n",
       "\n",
       "[272 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_labeled_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data into train_encodings, test_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(initial_labeled_set['text'].to_list(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_df['text'].to_list(), truncation=True, padding=True)\n",
    "train_labels = initial_labeled_set.coarse_label.to_list()\n",
    "test_labels = test_df.coarse_label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 6\n",
    "id_to_label = {0 : 'ABBR' , 1 : 'ENTY', 2: 'DESC', 3 : 'HUM', 4 : 'LOC', 5 : 'NUM'}\n",
    "label_to_id= { 'ABBR' : 0 , 'ENTY' : 1, 'DESC': 2, 'HUM' :3, 'LOC' : 4, 'NUM' : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, id2label = id_to_label, label2id = label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainingArguments, Dataloader, Metrics are needed to construct this Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # The output directory where the model predictions and checkpoints will be written\n",
    "    output_dir='./BERTModel2',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    #  The number of epochs, defaults to 3.0\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    # Number of steps used for a linear warmup\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy='steps',\n",
    "   # TensorBoard log directory\n",
    "    logging_dir='./multi-class-logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "          This construct a dict that is (index position) to encoding pairs.\n",
    "          Where the Encoding becomes tensor(Encoding), which is an requirements\n",
    "          for training the model\n",
    "        \"\"\"\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data items in the dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "\n",
    "    # Extract true labels from the input object\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    # Obtain predicted class labels by finding the column index with the maximum probability\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro',zero_division=1)\n",
    "\n",
    "    # Calculate the accuracy score using sklearn's accuracy_score function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Return the computed metrics as a dictionary\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling our Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_encodings,train_labels)\n",
    "test_dataloader = DataLoader(test_encodings,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    #the pre-trained bert model that will be fine-tuned\n",
    "    model=model,\n",
    "    #training arguments that we defined above\n",
    "    args=training_args,\n",
    "    train_dataset= train_dataloader,\n",
    "    eval_dataset = test_dataloader,\n",
    "    compute_metrics= compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train() #It's able to skip this and still make good prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let see the accuracy for our prediction our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24147e34b814a62b2d1b674c7b9fcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predictions.predictions.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.276 \n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_df['coarse_label'].to_list(),predicted_labels)\n",
    "print('accuracy {} '.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>coarse_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>Tell me what city the Kentucky Horse Park is n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>Who is the Incredible Hulk in reality ?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Why are electric cars less efficient in the no...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>What does `` E Pluribus Unum '' on the penny m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>What is the Hub of London ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  coarse_label\n",
       "1345  Tell me what city the Kentucky Horse Park is n...             4\n",
       "3519            Who is the Incredible Hulk in reality ?             3\n",
       "878   Why are electric cars less efficient in the no...             2\n",
       "5163  What does `` E Pluribus Unum '' on the penny m...             2\n",
       "1185                        What is the Hub of London ?             2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_labeled_set.head() # so we fine_tune with the inital_labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_labeled_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_for_each_row(class_probabilities):\n",
    "    \"\"\" Calculate entropy for each row in the array \"\"\"\n",
    "    return -tf.reduce_sum(class_probabilities * tf.math.log(class_probabilities),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      4\n",
       "2      3\n",
       "3      2\n",
       "4      5\n",
       "      ..\n",
       "495    3\n",
       "496    1\n",
       "497    5\n",
       "498    1\n",
       "499    2\n",
       "Name: coarse_label, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['coarse_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_calculate_entropy(data):\n",
    "    ''' Sample the Data '''\n",
    "    data_encodings = tokenizer(data['text'].to_list(), truncation=True, padding=True)\n",
    "    dataloader = DataLoader(data_encodings, data.coarse_label.to_list())\n",
    "\n",
    "    ''' Make predictions with class_probabilities and calculate entropy (uncertainty) '''\n",
    "    predictions = trainer.predict(dataloader)\n",
    "    prediction_probabilities = tf.constant(predictions.predictions)\n",
    "\n",
    "    ''' Predicted Labels '''\n",
    "    predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    ''' Prediction Probabilities '''\n",
    "    # Prediction probabilities, returning the highest probability for each instance\n",
    "    prediction_probabilities_max = np.amax(prediction_probabilities, axis=1)\n",
    "\n",
    "    # Calculate entropy for each instance\n",
    "    entropies = entropy_for_each_row(tf.nn.softmax(prediction_probabilities))\n",
    "\n",
    "    entropy_df = pd.DataFrame(\n",
    "        {'text' : data['text'].to_list(),\n",
    "         'predicted_Label': predicted_labels,\n",
    "         'predicted_Probability': prediction_probabilities_max,\n",
    "         'Entropy': entropies},\n",
    "        index=data.index\n",
    "    )\n",
    "\n",
    "    final_df = pd.concat([data['coarse_label'], entropy_df], axis=1)\n",
    "\n",
    "    return final_df.sort_values(by=['Entropy'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_and_train(data):\n",
    "\n",
    "    data_encodings = tokenizer(data['text'].to_list(), truncation=True, padding=True)\n",
    "    data_labels = data.coarse_label.to_list()\n",
    "\n",
    "    test_encodings = tokenizer(test_df['text'].to_list(), truncation=True, padding=True)\n",
    "    test_labels = test_df.coarse_label.to_list()\n",
    "\n",
    "    #Create Dataloader\n",
    "    train_dataloader = DataLoader(data_encodings,data_labels)\n",
    "    test_dataloader = DataLoader(test_encodings,test_labels) \n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        #the pre-trained bert model that will be fine-tuned\n",
    "        model=model,\n",
    "        #training arguments that we defined above\n",
    "        args=training_args,\n",
    "        train_dataset= train_dataloader,\n",
    "        eval_dataset = test_dataloader,\n",
    "        compute_metrics= test_dataloader\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad9afff33cf4c11af0b9026de2e5fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffb13415c1c49809e7c49373d8f473c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.624, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73987768b774731bf6c7ed27a2aa6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3472628593444824, 'eval_Accuracy': 0.586, 'eval_F1': 0.44060796701707866, 'eval_Precision': 0.7384507580240803, 'eval_Recall': 0.4825863061261837, 'eval_runtime': 0.6968, 'eval_samples_per_second': 717.611, 'eval_steps_per_second': 22.964, 'epoch': 2.94}\n",
      "{'train_runtime': 9.2792, 'train_samples_per_second': 87.939, 'train_steps_per_second': 5.496, 'train_loss': 1.622994060609855, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1794da4d5a4d99b7fd330bb2180a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e96faf9b81484e8671cdc7e07d0f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.117, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ff850741794989a19055adc2f538d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.970547616481781, 'eval_Accuracy': 0.722, 'eval_F1': 0.6236021829783662, 'eval_Precision': 0.8134894086692955, 'eval_Recall': 0.6213917061345651, 'eval_runtime': 0.7042, 'eval_samples_per_second': 710.028, 'eval_steps_per_second': 22.721, 'epoch': 2.94}\n",
      "{'train_runtime': 8.9941, 'train_samples_per_second': 90.726, 'train_steps_per_second': 5.67, 'train_loss': 1.117545578994003, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c9ac37d850425a90ca92975c92f28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a205c808404a81a7f61350ba41c814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5896, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e4e553ebd04067afdd8fca6c769b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5507956743240356, 'eval_Accuracy': 0.866, 'eval_F1': 0.7311907415809517, 'eval_Precision': 0.8982055965169394, 'eval_Recall': 0.7370056319154309, 'eval_runtime': 0.7093, 'eval_samples_per_second': 704.921, 'eval_steps_per_second': 22.557, 'epoch': 2.94}\n",
      "{'train_runtime': 9.0408, 'train_samples_per_second': 90.258, 'train_steps_per_second': 5.641, 'train_loss': 0.590410590171814, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bc99d1e37f4601989d75493eb5d1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1b6e290a084e79b895cf70f1f8f841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1934, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3890f2d3c1724aa8a93f9ccd174ef357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36938953399658203, 'eval_Accuracy': 0.896, 'eval_F1': 0.7509687572486553, 'eval_Precision': 0.9150933201698438, 'eval_Recall': 0.7564720009113061, 'eval_runtime': 0.7081, 'eval_samples_per_second': 706.159, 'eval_steps_per_second': 22.597, 'epoch': 2.94}\n",
      "{'train_runtime': 9.0663, 'train_samples_per_second': 90.003, 'train_steps_per_second': 5.625, 'train_loss': 0.1964872818367154, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1265ce88ce574b07982921cf5817991c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7df7fe179bf48989806f475816a0c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.062, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e578786366c4a91be23bd53b81bad77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28451189398765564, 'eval_Accuracy': 0.918, 'eval_F1': 0.8822363442084279, 'eval_Precision': 0.9266425299526354, 'eval_Recall': 0.8599007199433624, 'eval_runtime': 0.7115, 'eval_samples_per_second': 702.762, 'eval_steps_per_second': 22.488, 'epoch': 2.94}\n",
      "{'train_runtime': 9.0861, 'train_samples_per_second': 89.808, 'train_steps_per_second': 5.613, 'train_loss': 0.06372915179121728, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0a1d666810463189a5f23846c5aaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e60e79ab3b4bbcb53ab4629c2230f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0206, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9625b2d085444637b2632c1676f4691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3230632245540619, 'eval_Accuracy': 0.912, 'eval_F1': 0.8930663055614404, 'eval_Precision': 0.9277780801274638, 'eval_Recall': 0.8725050904056832, 'eval_runtime': 0.7172, 'eval_samples_per_second': 697.196, 'eval_steps_per_second': 22.31, 'epoch': 2.94}\n",
      "{'train_runtime': 9.0957, 'train_samples_per_second': 89.713, 'train_steps_per_second': 5.607, 'train_loss': 0.021438854582169476, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2efeb50a8d14a5b9da6b87542f1cbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1bb2567f6a45e4ab7deeecabcd916a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0076, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd26c2391ef46b693678db099d78eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3089001178741455, 'eval_Accuracy': 0.932, 'eval_F1': 0.9090653276523106, 'eval_Precision': 0.944967240693574, 'eval_Recall': 0.8869236701883737, 'eval_runtime': 0.7147, 'eval_samples_per_second': 699.635, 'eval_steps_per_second': 22.388, 'epoch': 2.94}\n",
      "{'train_runtime': 9.1419, 'train_samples_per_second': 89.26, 'train_steps_per_second': 5.579, 'train_loss': 0.007595811934009486, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3031c48202624e9b8c579894a82f834a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fa5fd653a24a48a29aca4b78a31585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0029, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3725ff60a97b491b90fdb69bd4841059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4120580554008484, 'eval_Accuracy': 0.92, 'eval_F1': 0.9008051511251756, 'eval_Precision': 0.9350775394296448, 'eval_Recall': 0.8813182299956174, 'eval_runtime': 0.71, 'eval_samples_per_second': 704.255, 'eval_steps_per_second': 22.536, 'epoch': 2.94}\n",
      "{'train_runtime': 9.1212, 'train_samples_per_second': 89.462, 'train_steps_per_second': 5.591, 'train_loss': 0.0030147394567143684, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1483a4f00c1241b39dab2eb38ffeafb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330dd308ad414a03954f5d93f8146645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8181bca67844dfad656b7e710f7658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3976462483406067, 'eval_Accuracy': 0.922, 'eval_F1': 0.8862912379295542, 'eval_Precision': 0.8807627156069869, 'eval_Recall': 0.8956258703598787, 'eval_runtime': 0.7111, 'eval_samples_per_second': 703.131, 'eval_steps_per_second': 22.5, 'epoch': 2.94}\n",
      "{'train_runtime': 9.1393, 'train_samples_per_second': 89.284, 'train_steps_per_second': 5.58, 'train_loss': 0.0012375229156996106, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d19e0172194f27a6190dadcabc120c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8deb91cd44c4f8b522c22468d5b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 2.5e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c31aabd6854268b915753228ac53a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4328893721103668, 'eval_Accuracy': 0.924, 'eval_F1': 0.9026753558158057, 'eval_Precision': 0.9362555245260098, 'eval_Recall': 0.8815033348322657, 'eval_runtime': 0.7171, 'eval_samples_per_second': 697.258, 'eval_steps_per_second': 22.312, 'epoch': 2.94}\n",
      "{'train_runtime': 9.1373, 'train_samples_per_second': 89.304, 'train_steps_per_second': 5.581, 'train_loss': 0.0005222474471392, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    sample_data = data.sample(n=10,random_state=42)\n",
    "    data.drop(sample_data.index,inplace = True)\n",
    "    entropy_prob_df = predict_and_calculate_entropy(sample_data)\n",
    "\n",
    "    #Let now apply active learning\n",
    "    text_encoding = tokenizer(entropy_prob_df['text'].to_list(),truncation=True,padding=True)\n",
    "    sample_dataloader = DataLoader(test_encodings, entropy_prob_df.coarse_label.to_list())\n",
    "\n",
    "    #test_df \n",
    "    test_encodings = tokenizer(test_df['text'].to_list(),truncation=True,padding=True)\n",
    "    test_dataloader = DataLoader(test_encodings, test_df.coarse_label.to_list())\n",
    "\n",
    "    trainer = Trainer(\n",
    "        #the pre-trained bert model that will be fine-tuned\n",
    "        model=model,\n",
    "        #training arguments that we defined above\n",
    "        args=training_args,\n",
    "        train_dataset= train_dataloader,\n",
    "        eval_dataset = test_dataloader,\n",
    "        compute_metrics= compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cd1b301d974e7ea7943bc7f79cb2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 92.2% \n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataloader)\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "accuracy = accuracy_score(test_df['coarse_label'].to_list(),predicted_labels)\n",
    "print('accuracy {}% '.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
